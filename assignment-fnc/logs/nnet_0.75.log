Namespace(model='nnet', skip_preprocess=True, train_prop='0.75')

Training a nnet model

Iteration 1, loss = 0.73811887
Iteration 2, loss = 0.48141716
Iteration 3, loss = 0.45440701
Iteration 4, loss = 0.44171686
Iteration 5, loss = 0.42844582
Iteration 6, loss = 0.41940127
Iteration 7, loss = 0.41416008
Iteration 8, loss = 0.40688796
Iteration 9, loss = 0.40365347
Iteration 10, loss = 0.39520700
Iteration 11, loss = 0.39435922
Iteration 12, loss = 0.38820171
Iteration 13, loss = 0.38600340
Iteration 14, loss = 0.38188840
Iteration 15, loss = 0.38104901
Iteration 16, loss = 0.37652887
Iteration 17, loss = 0.37461238
Iteration 18, loss = 0.37170386
Iteration 19, loss = 0.37075852
Iteration 20, loss = 0.37076357
Iteration 21, loss = 0.36730111
Iteration 22, loss = 0.36465334
Iteration 23, loss = 0.36292433
Iteration 24, loss = 0.36333593
Iteration 25, loss = 0.35995916
Iteration 26, loss = 0.35879036
Iteration 27, loss = 0.35816697
Iteration 28, loss = 0.35689555
Iteration 29, loss = 0.35609841
Iteration 30, loss = 0.35364296
Iteration 31, loss = 0.35187723
Iteration 32, loss = 0.35100876
Iteration 33, loss = 0.35008740
Iteration 34, loss = 0.35238722
Iteration 35, loss = 0.34793723
Iteration 36, loss = 0.34715435
Iteration 37, loss = 0.34723825
Iteration 38, loss = 0.34686175
Iteration 39, loss = 0.34477452
Iteration 40, loss = 0.34518129
Iteration 41, loss = 0.34373529
Iteration 42, loss = 0.34439666
Iteration 43, loss = 0.34273671
Iteration 44, loss = 0.34043805
Iteration 45, loss = 0.34083672
Iteration 46, loss = 0.34083615
Iteration 47, loss = 0.33988213
Iteration 48, loss = 0.33958998
Iteration 49, loss = 0.33777539
Iteration 50, loss = 0.33762281
Iteration 51, loss = 0.33814377
Iteration 52, loss = 0.34005816
Iteration 53, loss = 0.33759475
Iteration 54, loss = 0.33708133
Iteration 55, loss = 0.33573757
Iteration 56, loss = 0.33538062
Iteration 57, loss = 0.33526804
Iteration 58, loss = 0.33442733
Iteration 59, loss = 0.33541574
Iteration 60, loss = 0.33541980
Iteration 61, loss = 0.33224827
Iteration 62, loss = 0.33485816
Iteration 63, loss = 0.33367949
Iteration 64, loss = 0.33397179
Iteration 65, loss = 0.33266726
Iteration 66, loss = 0.33176608
Iteration 67, loss = 0.33297649
Iteration 68, loss = 0.33058207
Iteration 69, loss = 0.32898240
Iteration 70, loss = 0.33415068
Iteration 71, loss = 0.33084538
Iteration 72, loss = 0.32842364
Iteration 73, loss = 0.33119655
Iteration 74, loss = 0.32848352
Iteration 75, loss = 0.33157710
Iteration 76, loss = 0.33015452
Iteration 77, loss = 0.33078058
Iteration 78, loss = 0.32774827
Iteration 79, loss = 0.32797595
Iteration 80, loss = 0.32881280
Iteration 81, loss = 0.32728178
Iteration 82, loss = 0.32843499
Iteration 83, loss = 0.32721819
Iteration 84, loss = 0.32712640
Iteration 85, loss = 0.32666783
Iteration 86, loss = 0.32766849
Iteration 87, loss = 0.32600039
Iteration 88, loss = 0.32592351
Iteration 89, loss = 0.32625286
Iteration 90, loss = 0.32698894
Iteration 91, loss = 0.32843253
Iteration 92, loss = 0.32653257
Iteration 93, loss = 0.32480061
Iteration 94, loss = 0.32519636
Iteration 95, loss = 0.32428349
Iteration 96, loss = 0.32296316
Iteration 97, loss = 0.32649943
Iteration 98, loss = 0.32597078
Iteration 99, loss = 0.32469278
Iteration 100, loss = 0.32450324
Iteration 101, loss = 0.32350130
Iteration 102, loss = 0.32548076
Iteration 103, loss = 0.32322318
Iteration 104, loss = 0.32635840
Iteration 105, loss = 0.32314053
Iteration 106, loss = 0.32432062
Iteration 107, loss = 0.32425244
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Training time took 322.4174404144287 seconds

Trained a model using MLPClassifier(activation='relu', alpha=0.1, batch_size='auto', beta_1=0.9,
              beta_2=0.999, early_stopping=False, epsilon=1e-08,
              hidden_layer_sizes=(120, 120, 120), learning_rate='adaptive',
              learning_rate_init=0.001, max_iter=200, momentum=0.9,
              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,
              random_state=123, shuffle=True, solver='adam', tol=0.0001,
              validation_fraction=0.1, verbose=True, warm_start=False)
Train FNC Score:
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |   1607    |    67     |    625    |    472    |
-------------------------------------------------------------
| disagree  |    66     |    281    |    170    |    123    |
-------------------------------------------------------------
|  discuss  |    204    |    51     |   5649    |    755    |
-------------------------------------------------------------
| unrelated |    138    |    53     |    945    |   26273   |
-------------------------------------------------------------
Score: 14401.0 out of 16922.25	(85.10097652498929%)
Train F1 Score: 0.7363157229613977
Train Accuracy Score: 0.9021051789001842

Test FNC Score:
-------------------------------------------------------------
|           |   agree   | disagree  |  discuss  | unrelated |
-------------------------------------------------------------
|   agree   |    200    |     7     |   1029    |    667    |
-------------------------------------------------------------
| disagree  |    82     |     7     |    285    |    323    |
-------------------------------------------------------------
|  discuss  |    746    |    76     |   1738    |   1904    |
-------------------------------------------------------------
| unrelated |    385    |    17     |   1269    |   16678   |
-------------------------------------------------------------
Score: 6670.75 out of 11651.25	(57.2535135715052%)
Test F1 Score: 0.3533331989227708
Test Accuracy Score: 0.7328139141384331
